{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'load_dataset' from partially initialized module 'datasets' (most likely due to a circular import) (/Users/icheolhui/Documents/Github/Python/learn-pytorch/datasets.py)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# latest version\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mizumi-lab/llm-japanese-dataset-vanilla\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/Documents/Github/Python/learn-pytorch/datasets.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'load_dataset' from partially initialized module 'datasets' (most likely due to a circular import) (/Users/icheolhui/Documents/Github/Python/learn-pytorch/datasets.py)"]}],"source":["from datasets import load_dataset\n","\n","# latest version\n","\n","dataset = load_dataset(\"izumi-lab/llm-japanese-dataset-vanilla\")\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'load_dataset' from partially initialized module 'datasets' (most likely due to a circular import) (/Users/icheolhui/Documents/Github/Python/learn-pytorch/datasets.py)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n","File \u001b[0;32m~/Documents/Github/Python/learn-pytorch/datasets.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Dataset      \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'load_dataset' from partially initialized module 'datasets' (most likely due to a circular import) (/Users/icheolhui/Documents/Github/Python/learn-pytorch/datasets.py)"]}],"source":["import time\n","from train_japanese import load_dataset, Dataset\n","import transformers\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'load_dataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# latest version\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mizumi-lab/llm-japanese-dataset-vanilla\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"]}],"source":["# latest version\n","dataset = load_dataset(\"izumi-lab/llm-japanese-dataset-vanilla\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# 시간 측정을 위한 함수\n","def measure_time(func):\n","    def wrapper(*args, **kwargs):\n","        start_time = time.time()\n","        result = func(*args, **kwargs)\n","        end_time = time.time()\n","        print(f\"{func.__name__} took {end_time - start_time:.2f} seconds\")\n","        return result\n","    return wrapper"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load_data took 2.35 seconds\n"]}],"source":["# 데이터셋 로드\n","@measure_time\n","def load_data():\n","    return load_dataset(\"izumi-lab/llm-japanese-dataset-vanilla\")\n","dataset = load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': 2492588}\n","{'train': 3}\n","{'train': ['instruction', 'input', 'output']}\n","{'train': (2492588, 3)}\n"]}],"source":["print(dataset.num_rows)\n","print(dataset.num_columns)\n","print(dataset.column_names)\n","print(dataset.shape)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:53, 17.71s/it]"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(model_id)\n","\n","# Add a padding token if it doesn't exist\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    model.resize_token_embeddings(len(tokenizer))\n","\n","\n","\n","# Prepare dataset for training\n","def format_dataset(example):\n","    return {\n","        \"input_ids\": tokenizer(example[\"input\"], truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"],\n","        \"labels\": tokenizer(example[\"output\"], truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n","    }\n","\n","train_dataset = dataset[\"train\"].map(format_dataset, batched=True)\n","\n","# LoRA configuration\n","peft_config = LoraConfig(\n","    r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",")\n","\n","# # 텍스트 생성 파이프라인 설정\n","# pipeline = transformers.pipeline(\n","#     \"text-generation\",\n","#     model=model_id,\n","#     model_kwargs={\"torch_dtype\": torch.bfloat16, \"rope_scaling\": {\"type\": \"dynamic\", \"factor\": 8.0}},\n","#     device_map=\"auto\",\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델에 LoRA 적용\n","@measure_time\n","def apply_lora(model, config):\n","    return get_peft_model(model, config)\n","model = apply_lora(model, peft_config)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=16,\n","    learning_rate=2e-4,\n","    num_train_epochs=3,\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    fp16=True,\n","    push_to_hub=False\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    tokenizer=tokenizer\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 미세 조정\n","@measure_time\n","def train_model():\n","    trainer.train()\n","\n","train_model()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 이전과 결과 비교\n","@measure_time\n","def evaluate_model():\n","    return trainer.evaluate()\n","\n","evaluation_results = evaluate_model()\n","print(evaluation_results)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
